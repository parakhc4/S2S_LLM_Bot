{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def speech_to_text():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Adjusting for ambient noise...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1) \n",
    "        print(\"Please speak...\")\n",
    "        try:\n",
    "            audio_data = recognizer.listen(source, timeout=5) \n",
    "            print(\"Recognizing with PocketSphinx...\")\n",
    "            text = recognizer.recognize_sphinx(audio_data)\n",
    "            print(\"Recognized Text: \" + text)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand the audio.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_meaning(input):\n",
    "    monster_api_key = os.getenv('MONSTER_API_KEY')\n",
    "\n",
    "    generation_model_name: str\n",
    "    temperature: float = 0.9\n",
    "    top_p = 0.9\n",
    "    max_tokens: int = 2048\n",
    "    stream: bool = False  \n",
    "    llm_name: str = \"Meta-Llama\"\n",
    "\n",
    "    monster_client = OpenAI(\n",
    "        base_url=\"https://llm.monsterapi.ai/v1/\",\n",
    "        api_key=monster_api_key\n",
    "    )\n",
    "\n",
    "    monster_ai_model_name = {\n",
    "        \"Google-Gemma\": \"google/gemma-2-9b-it\",\n",
    "        \"Mistral\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"Microsoft-Phi\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        \"Meta-Llama\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    }\n",
    "    message = [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant. Kindly answer the following question:\"},\n",
    "                {\"role\": \"user\", \"content\": input}\n",
    "            ]\n",
    "\n",
    "    response = monster_client.chat.completions.create( model=monster_ai_model_name[llm_name], messages=message, temperature=temperature, top_p=top_p, max_tokens=max_tokens, stream=False)\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_output(output):\n",
    "    language = \"en\"\n",
    "    myobj = gTTS(text=output,lang = language,slow = False)\n",
    "    myobj.save(\"welcome.mp3\")\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(\"welcome.mp3\")\n",
    "    pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.16.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Adjusting for ambient noise...\n",
      "Please speak...\n",
      "Recognizing with PocketSphinx...\n",
      "Recognized Text: you spoke\n"
     ]
    }
   ],
   "source": [
    "# orchestrator\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Glass()) as interface:\n",
    "    gr.Markdown(\"## Speech 2 Speech LLM Application\")\n",
    "    gr.Markdown(\"_Developed for Tensorgo_\")\n",
    "    \n",
    "    with gr.Tab(\"üé§ Ask Your Question\"):\n",
    "        input_box = gr.Textbox(label=\"Input Text\", placeholder=\"Speak or type your query here...\")\n",
    "        output_text_box = gr.Textbox(label=\"Output Text\")\n",
    "        output_audio = gr.Audio(label=\"TTS Output\", type=\"filepath\",autoplay=True)\n",
    "        mic_button = gr.Button(\"üéôÔ∏è Speak Now\")\n",
    "        process_button = gr.Button(\"üîç Process Query\")\n",
    "        def process_query(input_text):\n",
    "            # Check if input_text is empty\n",
    "            if not input_text.strip():\n",
    "                return \"Please provide a query.\", None\n",
    "            \n",
    "            # Process the input text using LLM\n",
    "            output_text = text_to_meaning(input_text)\n",
    "            \n",
    "            # Generate TTS output\n",
    "            language = \"en\"\n",
    "            tts = gTTS(text=output_text, lang=language, slow=False)\n",
    "            tts_file = \"output.mp3\"\n",
    "            tts.save(tts_file)\n",
    "            \n",
    "            return output_text, tts_file\n",
    "        process_button.click(process_query, inputs=input_box, outputs=[output_text_box, output_audio])\n",
    "        mic_button.click(speech_to_text, outputs=input_box)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
